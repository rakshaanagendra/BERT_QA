# ğŸ§  BERT Question Answering (Extractive QA with FastAPI + MLflow)

![FastAPI Screenshot](./fastapi.png)

![Python](https://img.shields.io/badge/Python-3.10-blue)
![FastAPI](https://img.shields.io/badge/API-FastAPI-green)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-orange)
![MLflow](https://img.shields.io/badge/Tracking-MLflow-yellow)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## ğŸ“˜ Overview

This project implements an **Extractive Question Answering (QA)** system using a fine-tuned **DistilBERT** model on the **SQuAD** dataset.  
It can answer questions based on a given context paragraph, deployed through a **FastAPI** web service and tracked using **MLflow** for experiment logging.

**Example:**

> **Question:** Who created Python?
>   
> **Context:** Python was created by Guido van Rossum in 1991.
>   
> **Answer:** Guido van Rossum âœ…

---

## âš™ï¸ Tech Stack

| Category | Tool / Library |
|-----------|----------------|
| Model | `distilbert-base-cased-distilled-squad` |
| Framework | PyTorch, Hugging Face Transformers |
| API | FastAPI + Uvicorn |
| Experiment Tracking | MLflow |
| Visualization | Pandas Token Table |
| Language | Python 3.10 |
| Environment | Local CPU |

---

## ğŸ§© Features

- ğŸ§  **BERT-based Extractive QA** â†’ Finds exact text spans that answer questions  
- âš™ï¸ **FastAPI endpoint** â†’ Interactive `/predict` API  
- ğŸ“Š **MLflow integration** â†’ Logs question, answer, confidence, and model version  
- ğŸ§¾ **Batch evaluation** â†’ Log multiple QA pairs in a single script  
- ğŸ–¼ï¸ **Token visualization** â†’ See start/end logits and confidence scores  
- ğŸš€ **Swagger UI** â†’ Easy question testing at `/docs`

---

## ğŸ§® Example Output

>Question: Who created Python?
>
>Predicted Answer: Guido van Rossum
>
>Confidence: 0.982
>
>Start Index: 10
>
>End Index: 14

---

## ğŸš€ Run Locally

### ğŸ§° 1. Clone the repository

```bash
git clone https://github.com/rakshaanagendra/BERT_QA.git
cd BERT_QA
```

### âš™ï¸ 2. Create virtual environment

```bash
python -m venv venv
.\venv\Scripts\activate
```

### ğŸ“¦ 3. Install dependencies
```bash
pip install -r requirements.txt
```

### â–¶ï¸ 4. Run the FastAPI server

```bash
uvicorn app.main:app --reload
Then open your browser â†’ http://127.0.0.1:8000/docs
```
### ğŸ§  Example API Request
{
  "question": "Who created Python?",
  "context": "Python was created by Guido van Rossum in 1991."
}
### Response
{
  "question": "Who created Python?",
  "predicted_answer": "Guido van Rossum",
  "confidence": 0.982
}

---

## ğŸ“Š MLflow Experiment Tracking
```bash
mlflow ui
Open http://127.0.0.1:5000
```

Youâ€™ll see:
- Parameters â†’ model, question, context length
- Metrics â†’ confidence, start/end indices
- Artifacts â†’ predicted answer text files

--- 


